## 摘要

深度生成模型使高分辨率逼真图像合成成为可能。但这仍然不能满足许多应用的需求：可控内容创作。虽然近几年的工作集中在如何解耦数据变化的潜在因素上，但这些研究大部分仍然在二维空间进行操作却忽略了我们的世界是三维的事实。此外，只有少数工作考虑了场景的合成性质。我们关键的研究假设就在于将合成3D场景表达并入到生成模型中从而使图像合成更可控。在无监督情景下使用非结构化且未定位姿态的图像集进行学习时，将场景表示为合成神经特征字段有助于从背景中解耦